# Обучение модели (BERT) классификации комментариев

## Описание проекта

Интернет-магазин «Y» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в Y-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

Необходимо обучить модель классифицировать комментарии на позитивные и негативные. В распоряжении набор данных с разметкой о токсичности. Требование бизнеса - модель со значением метрики качества F1 не меньше 0.75.

## Ключевые слова проекта

`обработка естественного языка` `NLP` `классификация` `подбор гиперпараметров` `выбор модели МО`

## Навыки и инструменты

`исследовательский анализ данных` `Python` `Pandas` `NumPy` `Scikit-learn` `Re` `Nltk` `Tqdm` `Lightgbm` `Catboost` `Torch` `Transformers`

## Результаты исследования

**I. В результате загрузки данных, установлено:**

1.  DataFrame содержит 159571 строк и 2 столбца.
2.  В столбце «text» данные типа object, пропуски отсутствуют.
3.  В столбце «toxic» данные типа int64, пропуски отсутствуют.
4.  Явные дубликаты отсутствуют.

**II. В результате предобработки:**

1. Произведена очистка данных и лемматизация (для BERT можно и не делать лемматизацию, она и так хорошо справляется).
2. Выбрано случайным образом 500 строк, ввиду ресурсоёмкости обработки всего массива данных.
3. Установлено, что соотношение класса '0' и '1' соответственно: 0.88 : 0.12, данный факт указывает на необходимость балансировки, однако, для начала необходимо подготовить модели.

**III. В результате подготовки модели, а также features & target:**

1.  Загружена предобученная модель `BertModel`.
2.  Выполнена токенизация и кодирование строк.
3.  Выполнена подрезка длинны токенов (не должно превышать 512 (обусловлено особенностями используемой модели BERT) 
4.  Выборка разделена на тренировочную и тестовую (75:25).

**IV. В результате обучения и подбора лучших параметров моделей на default данных, установлено:**

1. Лучшая модель: LogisticRegression.
2. Параметры лучшей модели: C=18, class_weight='balanced'.
3. Качество модели (F1): 0.444.
4. Не высокое качество модели обусловлено дисбалансом классов.

**V. В результате поиска множителя балансировки, а также подбора лучших параметров моделей на custom данных, установлено:**

1. Высокое качество модели RandomForestClassifier(max_depth=8, n_estimators=25) достигается на множителе - 4.
2. Значение F1: 0.86.
3. Время поиска множителя для балансировки и параметров модели порядка: 8 мин.

**VI. В результате проверки качества модели на тестовой выборке, установлено:**

1. для best_model_on_data_default
  * F1 лучшей модели LogisticRegression(C=18, class_weight='balanced') на тестовой выборке: 0.52;
  * Требование бизнеса (F1 не меньше 0.75) – не выполнено;
2. для best_model_on_data_custom
  * F1 лучшей модели RandomForestClassifier(max_depth=8, n_estimators=25) на тестовой выборке: 0.96;
  * Множитель, увеличивающий выборку - 4;
  * Требование бизнеса (F1 не меньше 0.75) - выполнено.
 
 ## Статус проекта
 `Завершен`
