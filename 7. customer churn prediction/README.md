# Прогнозирование оттока клиента банка

## Описание проекта

Из банка стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.
Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.

## Ключевые слова проекта

`классификация` `подбор гиперпараметров` `выбор модели МО`

## Навыки и инструменты

`исследовательский анализ данных` `Python` `Pandas` `Matplotlib` `NumPy` `Math` `SciPy` `Seaborn` `Scikit-learn`

## Результаты исследования

**В результате подготовки данных, установлено:**

1. Пропусков в столбце "Tenure" порядка 9% (проведена замена на медианные значения).
2. Необходимо удалить столбцы 'CustomerId', 'RowNumber', 'Surname' из признаков (они не несут полезной информации для предсказания).

**В результате исследования:**

1. Соотношение в данных 8:2.
2. Проведено порядковое кодирование (применение прямого привело бы к излишне большому количеству столбцов, что не к чему).
3. Применено масштабирование к столбцам 'CreditScore', 'Age', 'Tenure', 'Balance','EstimatedSalary'.
4. Выполнено деление на обучающую и валидационно-тестовую выборку (60:40).
5. Выполнено деление валидационно-тестовой выборки (50:50).
6. Установлено F1 лучшей модели (DecisionTreeClassifier): 0.57 с параметрами (max_depth=6, random_state=12345).
7. Установлено F1 лучшей модели (RandomForestClassifier): 0.538 с параметрами (max_depth=4, n_estimators=9, random_state=12345).
8. Установлено F1 лучшей модели (LogisticRegression): 0.331 с параметрами (max_iter=1000, random_state=12345, solver='saga').
9. В среднем наибольший прирост F1 по всем моделям, при увеличении выборки, дает МНОЖИТЕЛЬ - х3
10. Наибольший прирост F1 по DecisionTreeClassifier_model, при уменьшении выборки, дает МНОЖИТЕЛЬ - х0.6
11. Наибольший прирост F1 по RandomForestClassifier_model, при уменьшении выборки, дает МНОЖИТЕЛЬ - х0.3
12. Наибольший прирост F1 по LogisticRegression_model, при уменьшении выборки, дает МНОЖИТЕЛЬ - х0.4

**В результате тестирования, установлено:**
1. Наилучшая модель на тестовой выборке: DecisionTreeClassifier
2. Параметры модели: max_depth=5, random_state=12345
3. Значение F1 = 0.591
4. Площадь под ROC-кривой: 0.822

![image](https://user-images.githubusercontent.com/104613549/181459074-a2d9f156-715a-4547-91d4-3a0ef10e19e1.png)
 
 ## Статус проекта
 `Завершен`
