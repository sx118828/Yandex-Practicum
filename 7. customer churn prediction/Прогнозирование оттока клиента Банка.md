## Подготовка данных


```python
import pandas as pd
import matplotlib.pyplot as plt 
import seaborn as sns
from scipy import stats as st
import numpy as np
import warnings
import math

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression

from sklearn.preprocessing import OrdinalEncoder
from sklearn.preprocessing import StandardScaler 
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import roc_curve 
from sklearn.metrics import roc_auc_score
```


```python
# просмотр, где находится каталог с файлами на COLAB
from google.colab import drive
drive.mount('/content/drive')
```

    Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).
    


```python
# получить доступ к каталогу и уточнить названия папок
import os
os.listdir('/content/drive/My Drive/Colab Notebooks/Яндекс/Проект 6 Отток клиентов')
```




    ['Churn.csv', 'ПРАВКА', 'Отток клиентов.ipynb', 'GitHub']




```python
# загружаем данные
data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Яндекс/Проект 6 Отток клиентов/Churn.csv')
```


```python
# просмотр типов данных и кол-ва ненулевых значений
data.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 10000 entries, 0 to 9999
    Data columns (total 14 columns):
     #   Column           Non-Null Count  Dtype  
    ---  ------           --------------  -----  
     0   RowNumber        10000 non-null  int64  
     1   CustomerId       10000 non-null  int64  
     2   Surname          10000 non-null  object 
     3   CreditScore      10000 non-null  int64  
     4   Geography        10000 non-null  object 
     5   Gender           10000 non-null  object 
     6   Age              10000 non-null  int64  
     7   Tenure           9091 non-null   float64
     8   Balance          10000 non-null  float64
     9   NumOfProducts    10000 non-null  int64  
     10  HasCrCard        10000 non-null  int64  
     11  IsActiveMember   10000 non-null  int64  
     12  EstimatedSalary  10000 non-null  float64
     13  Exited           10000 non-null  int64  
    dtypes: float64(3), int64(8), object(3)
    memory usage: 1.1+ MB
    


```python
# подсчет нулевых значений
data.isna().sum()
```




    RowNumber            0
    CustomerId           0
    Surname              0
    CreditScore          0
    Geography            0
    Gender               0
    Age                  0
    Tenure             909
    Balance              0
    NumOfProducts        0
    HasCrCard            0
    IsActiveMember       0
    EstimatedSalary      0
    Exited               0
    dtype: int64



909/10000*100=9% - пропусков, более 1%. Удалять не безопасно, заполним медианными значениями.


```python
# заполнение пропусков медианными значениями
data['Tenure'] = data['Tenure'].fillna(data['Tenure'].median())
```


```python
data
```





  <div id="df-a5a1e502-c603-4a94-9801-a94079c57867">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>RowNumber</th>
      <th>CustomerId</th>
      <th>Surname</th>
      <th>CreditScore</th>
      <th>Geography</th>
      <th>Gender</th>
      <th>Age</th>
      <th>Tenure</th>
      <th>Balance</th>
      <th>NumOfProducts</th>
      <th>HasCrCard</th>
      <th>IsActiveMember</th>
      <th>EstimatedSalary</th>
      <th>Exited</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>15634602</td>
      <td>Hargrave</td>
      <td>619</td>
      <td>France</td>
      <td>Female</td>
      <td>42</td>
      <td>2.0</td>
      <td>0.00</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>101348.88</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>15647311</td>
      <td>Hill</td>
      <td>608</td>
      <td>Spain</td>
      <td>Female</td>
      <td>41</td>
      <td>1.0</td>
      <td>83807.86</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>112542.58</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>15619304</td>
      <td>Onio</td>
      <td>502</td>
      <td>France</td>
      <td>Female</td>
      <td>42</td>
      <td>8.0</td>
      <td>159660.80</td>
      <td>3</td>
      <td>1</td>
      <td>0</td>
      <td>113931.57</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>15701354</td>
      <td>Boni</td>
      <td>699</td>
      <td>France</td>
      <td>Female</td>
      <td>39</td>
      <td>1.0</td>
      <td>0.00</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>93826.63</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>15737888</td>
      <td>Mitchell</td>
      <td>850</td>
      <td>Spain</td>
      <td>Female</td>
      <td>43</td>
      <td>2.0</td>
      <td>125510.82</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>79084.10</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>9995</th>
      <td>9996</td>
      <td>15606229</td>
      <td>Obijiaku</td>
      <td>771</td>
      <td>France</td>
      <td>Male</td>
      <td>39</td>
      <td>5.0</td>
      <td>0.00</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>96270.64</td>
      <td>0</td>
    </tr>
    <tr>
      <th>9996</th>
      <td>9997</td>
      <td>15569892</td>
      <td>Johnstone</td>
      <td>516</td>
      <td>France</td>
      <td>Male</td>
      <td>35</td>
      <td>10.0</td>
      <td>57369.61</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>101699.77</td>
      <td>0</td>
    </tr>
    <tr>
      <th>9997</th>
      <td>9998</td>
      <td>15584532</td>
      <td>Liu</td>
      <td>709</td>
      <td>France</td>
      <td>Female</td>
      <td>36</td>
      <td>7.0</td>
      <td>0.00</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>42085.58</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9998</th>
      <td>9999</td>
      <td>15682355</td>
      <td>Sabbatini</td>
      <td>772</td>
      <td>Germany</td>
      <td>Male</td>
      <td>42</td>
      <td>3.0</td>
      <td>75075.31</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>92888.52</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9999</th>
      <td>10000</td>
      <td>15628319</td>
      <td>Walker</td>
      <td>792</td>
      <td>France</td>
      <td>Female</td>
      <td>28</td>
      <td>5.0</td>
      <td>130142.79</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>38190.78</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>10000 rows × 14 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-a5a1e502-c603-4a94-9801-a94079c57867')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-a5a1e502-c603-4a94-9801-a94079c57867 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-a5a1e502-c603-4a94-9801-a94079c57867');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>




## Вывод

**В результате подготовки данных, установлено:**

1. Пропусков в столбце "Tenure" порядка 9% (проведена замена на медианные значения).
2. Необходимо удалить столбцы 'CustomerId', 'RowNumber', 'Surname' из признаков (они не несут полезной информации для предсказания).

## Исследование задачи


```python
# удаление столбцов из признаков
# назначение целевого признака
features = data.drop(['Exited', 'CustomerId', 'RowNumber', 'Surname'], axis=1)
target = data['Exited']
```


```python

```


```python
# прямое кодирование
features = pd.get_dummies(features, drop_first=True)
```


```python
# исследование баланса классов
features_zeros = features[target == 0] 
features_ones = features[target == 1] 

target_zeros  = target[target == 0] 
target_ones = target[target == 1] 

print(features_zeros.shape)
print(features_ones.shape)
print(target_zeros.shape)
print(target_ones.shape)
```

    (7963, 11)
    (2037, 11)
    (7963,)
    (2037,)
    

Соотношение 8:2


```python
# масштабирование признаков
numeric = ['CreditScore', 'Age', 'Tenure', 'Balance','EstimatedSalary']

scaler = StandardScaler()
scaler.fit(features[numeric])
features[numeric] = scaler.transform(features[numeric])
```


```python
# результат масштабирования
features
```





  <div id="df-2a81d3b0-375c-4337-9af8-272aa63c5dbe">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CreditScore</th>
      <th>Age</th>
      <th>Tenure</th>
      <th>Balance</th>
      <th>NumOfProducts</th>
      <th>HasCrCard</th>
      <th>IsActiveMember</th>
      <th>EstimatedSalary</th>
      <th>Geography_Germany</th>
      <th>Geography_Spain</th>
      <th>Gender_Male</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-0.326221</td>
      <td>0.293517</td>
      <td>-1.086246</td>
      <td>-1.225848</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0.021886</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.440036</td>
      <td>0.198164</td>
      <td>-1.448581</td>
      <td>0.117350</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0.216534</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.536794</td>
      <td>0.293517</td>
      <td>1.087768</td>
      <td>1.333053</td>
      <td>3</td>
      <td>1</td>
      <td>0</td>
      <td>0.240687</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.501521</td>
      <td>0.007457</td>
      <td>-1.448581</td>
      <td>-1.225848</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>-0.108918</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.063884</td>
      <td>0.388871</td>
      <td>-1.086246</td>
      <td>0.785728</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>-0.365276</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>9995</th>
      <td>1.246488</td>
      <td>0.007457</td>
      <td>0.000761</td>
      <td>-1.225848</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>-0.066419</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9996</th>
      <td>-1.391939</td>
      <td>-0.373958</td>
      <td>1.812439</td>
      <td>-0.306379</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0.027988</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9997</th>
      <td>0.604988</td>
      <td>-0.278604</td>
      <td>0.725432</td>
      <td>-1.225848</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>-1.008643</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>9998</th>
      <td>1.256835</td>
      <td>0.293517</td>
      <td>-0.723910</td>
      <td>-0.022608</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>-0.125231</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9999</th>
      <td>1.463771</td>
      <td>-1.041433</td>
      <td>0.000761</td>
      <td>0.859965</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>-1.076370</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>10000 rows × 11 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-2a81d3b0-375c-4337-9af8-272aa63c5dbe')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-2a81d3b0-375c-4337-9af8-272aa63c5dbe button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-2a81d3b0-375c-4337-9af8-272aa63c5dbe');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>





```python
# деление на обучающую и валидационно-тестовую выборку (60:40)
features_train, features_valid_test, target_train, target_valid_test = train_test_split(
    features, target, test_size=0.4, random_state=12345)
```


```python
# деление валидационно-тестовой выборки (50:50)
features_valid, features_test, target_valid, target_test = train_test_split(
    features_valid_test, target_valid_test, test_size=0.5, random_state=12345)
```

### Решающее дерево - DecisionTreeClassifier


```python
# функция поиска лучшей модели DecisionTreeClassifier
def DecisionTreeClassifier_model(features_train, target_train):
  best_model_DecisionTreeClassifier = None
  best_result = 0
  for depth in range(1, 10):
    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)
    model.fit(features_train, target_train)
    predictions_valid = model.predict(features_valid) 
    result = f1_score(target_valid, predictions_valid) 
    if result > best_result:
      best_model_DecisionTreeClassifier = model
      best_result = result
  
  print("F1 лучшей модели (DecisionTreeClassifier):", round(best_result, 3))   
  return best_model_DecisionTreeClassifier

```


```python
# проверка работы функции
DecisionTreeClassifier_model(features_train, target_train)
```

    F1 лучшей модели (DecisionTreeClassifier): 0.57
    




    DecisionTreeClassifier(max_depth=6, random_state=12345)



### Решающий лес - RandomForestClassifier


```python
# функция поиска лучшей модели RandomForestClassifier
def RandomForestClassifier_model(features_train, target_train):
  best_model_RandomForestClassifier = None
  best_result = 0
  for est in range(1, 11):
    for depth in range(1, 6):
      model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth) 
      model.fit(features_train, target_train) 
      predictions_valid = model.predict(features_valid) 
      result = f1_score(target_valid, predictions_valid) 
      if result > best_result:
        best_model_RandomForestClassifier = model 
        best_result = result
  
  print("F1 лучшей модели (RandomForestClassifier):", round(best_result, 3))
  return best_model_RandomForestClassifier
```


```python
# проверка работы функции
RandomForestClassifier_model(features_train, target_train)
```

    F1 лучшей модели (RandomForestClassifier): 0.538
    




    RandomForestClassifier(max_depth=4, n_estimators=9, random_state=12345)



### Логистическая регрессия - LogisticRegression


```python
# функция поиска лучшей модели LogisticRegression
def LogisticRegression_model(features_train, target_train):
  list_solver = ['saga', 'lbfgs', 'liblinear', 'sag', 'newton-cg']
  best_model_LogisticRegression = None
  best_result = 0
  for sol in list_solver:
    model = LogisticRegression(random_state=12345, solver=sol, max_iter=1000)
    model.fit(features_train, target_train)
    predictions_valid = model.predict(features_valid)
    result = f1_score(target_valid, predictions_valid)
    if best_result < result:
      best_result = result
      best_model_LogisticRegression = model
  
  print("F1 лучшей модели (LogisticRegression):", round(best_result, 3))   
  return best_model_LogisticRegression
```


```python
# проверка работы функции
LogisticRegression_model(features_train, target_train)
```

    F1 лучшей модели (LogisticRegression): 0.331
    




    LogisticRegression(max_iter=1000, random_state=12345, solver='saga')



## Вывод

**В результате исследования, установлено:**

1. Соотношение в данных 8:2.
2. Проведено порядковое кодирование (применение прямого привело бы к излишне большому количеству столбцов, что не к чему).
3. Применено масштабирование к столбцам 'CreditScore', 'Age', 'Tenure', 'Balance','EstimatedSalary'.
4. Выполнено деление на обучающую и валидационно-тестовую выборку (60:40).
5. Выполнено деление валидационно-тестовой выборки (50:50).
6. Установлено F1 лучшей модели (DecisionTreeClassifier): 0.57 с параметрами (max_depth=6, random_state=12345).
7. Установлено F1 лучшей модели (RandomForestClassifier): 0.538 с параметрами (max_depth=4, n_estimators=9, random_state=12345).
8. Установлено F1 лучшей модели (LogisticRegression): 0.331 с параметрами (max_iter=1000, random_state=12345, solver='saga').

## Устранение дисбаланса


```python
# функция увеличение выборки
def upsample(features, target, repeat):
    features_zeros = features[target == 0]
    features_ones = features[target == 1]
    target_zeros = target[target == 0]
    target_ones = target[target == 1]

    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)
    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)
    
    features_upsampled, target_upsampled = shuffle(
        features_upsampled, target_upsampled, random_state=12345)
    
    return features_upsampled, target_upsampled

features_upsampled, target_upsampled = upsample(features_train, target_train, 3)
```


```python
# поиск наиболее оптимального значения МНОЖИТЕЛЯ (хN), увеличивающего выборку
for j in range(1, 5):
  features_upsampled, target_upsampled = upsample(features_train, target_train, j)
  print('при увеличения на: х_', j)
  DecisionTreeClassifier_model(features_upsampled, target_upsampled)
```

    при увеличения на: х_ 1
    F1 лучшей модели (DecisionTreeClassifier): 0.57
    при увеличения на: х_ 2
    F1 лучшей модели (DecisionTreeClassifier): 0.598
    при увеличения на: х_ 3
    F1 лучшей модели (DecisionTreeClassifier): 0.586
    при увеличения на: х_ 4
    F1 лучшей модели (DecisionTreeClassifier): 0.596
    


```python
# поиск наиболее оптимального значения МНОЖИТЕЛЯ (хN), увеличивающего выборку
for j in range(1, 5):
  features_upsampled, target_upsampled = upsample(features_train, target_train, j)
  print('при увеличения на: х_', j)
  RandomForestClassifier_model(features_upsampled, target_upsampled)
```

    при увеличения на: х_ 1
    F1 лучшей модели (RandomForestClassifier): 0.587
    при увеличения на: х_ 2
    F1 лучшей модели (RandomForestClassifier): 0.603
    при увеличения на: х_ 3
    F1 лучшей модели (RandomForestClassifier): 0.612
    при увеличения на: х_ 4
    F1 лучшей модели (RandomForestClassifier): 0.611
    


```python
# поиск наиболее оптимального значения МНОЖИТЕЛЯ (хN), увеличивающего выборку
for j in range(1, 5):
  features_upsampled, target_upsampled = upsample(features_train, target_train, j)
  print('при увеличения на: х_', j)
  LogisticRegression_model(features_upsampled, target_upsampled)
```

    при увеличения на: х_ 1
    F1 лучшей модели (LogisticRegression): 0.331
    при увеличения на: х_ 2
    F1 лучшей модели (LogisticRegression): 0.464
    при увеличения на: х_ 3
    F1 лучшей модели (LogisticRegression): 0.5
    при увеличения на: х_ 4
    F1 лучшей модели (LogisticRegression): 0.489
    

## Вывод

В среднем наибольший прирост F1 по всем моделям, при увеличении выборки, дает МНОЖИТЕЛЬ - х3


```python
# функция уменьшения выборки
def downsample(features, target, fraction):
    features_zeros = features[target == 0]
    features_ones = features[target == 1]
    target_zeros = target[target == 0]
    target_ones = target[target == 1]

    features_downsampled = pd.concat(
        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])
    target_downsampled = pd.concat(
        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])
    
    features_downsampled, target_downsampled = shuffle(
        features_downsampled, target_downsampled, random_state=12345)
    
    return features_downsampled, target_downsampled

features_downsampled, target_downsampled = downsample(features_train, target_train, 0.6)
```


```python
# поиск наиболее оптимального значения МНОЖИТЕЛЯ (хN), уменьшающего выборку
for j in  np.arange(0.1, 0.9, 0.1):
  features_downsampled, target_downsampled = downsample(features_train, target_train, j)
  print('при уменьшении на: х_', j)
  DecisionTreeClassifier_model(features_downsampled, target_downsampled)
```

    при уменьшении на: х_ 0.1
    F1 лучшей модели (DecisionTreeClassifier): 0.496
    при уменьшении на: х_ 0.2
    F1 лучшей модели (DecisionTreeClassifier): 0.549
    при уменьшении на: х_ 0.30000000000000004
    F1 лучшей модели (DecisionTreeClassifier): 0.579
    при уменьшении на: х_ 0.4
    F1 лучшей модели (DecisionTreeClassifier): 0.569
    при уменьшении на: х_ 0.5
    F1 лучшей модели (DecisionTreeClassifier): 0.584
    при уменьшении на: х_ 0.6
    F1 лучшей модели (DecisionTreeClassifier): 0.587
    при уменьшении на: х_ 0.7000000000000001
    F1 лучшей модели (DecisionTreeClassifier): 0.58
    при уменьшении на: х_ 0.8
    F1 лучшей модели (DecisionTreeClassifier): 0.577
    


```python
# поиск наиболее оптимального значения МНОЖИТЕЛЯ (хN), уменьшающего выборку
for j in  np.arange(0.1, 0.9, 0.1):
  features_downsampled, target_downsampled = downsample(features_train, target_train, j)
  print('при уменьшении на: х_', j)
  RandomForestClassifier_model(features_downsampled, target_downsampled)
```

    при уменьшении на: х_ 0.1
    F1 лучшей модели (RandomForestClassifier): 0.451
    при уменьшении на: х_ 0.2
    F1 лучшей модели (RandomForestClassifier): 0.589
    при уменьшении на: х_ 0.30000000000000004
    F1 лучшей модели (RandomForestClassifier): 0.621
    при уменьшении на: х_ 0.4
    F1 лучшей модели (RandomForestClassifier): 0.609
    при уменьшении на: х_ 0.5
    F1 лучшей модели (RandomForestClassifier): 0.611
    при уменьшении на: х_ 0.6
    F1 лучшей модели (RandomForestClassifier): 0.594
    при уменьшении на: х_ 0.7000000000000001
    F1 лучшей модели (RandomForestClassifier): 0.585
    при уменьшении на: х_ 0.8
    F1 лучшей модели (RandomForestClassifier): 0.566
    


```python
# поиск наиболее оптимального значения МНОЖИТЕЛЯ (хN), уменьшающего выборку
for j in  np.arange(0.1, 0.9, 0.1):
  features_downsampled, target_downsampled = downsample(features_train, target_train, j)
  print('при уменьшении на: х_', j)
  LogisticRegression_model(features_downsampled, target_downsampled)
```

    при уменьшении на: х_ 0.1
    F1 лучшей модели (LogisticRegression): 0.43
    при уменьшении на: х_ 0.2
    F1 лучшей модели (LogisticRegression): 0.479
    при уменьшении на: х_ 0.30000000000000004
    F1 лучшей модели (LogisticRegression): 0.497
    при уменьшении на: х_ 0.4
    F1 лучшей модели (LogisticRegression): 0.505
    при уменьшении на: х_ 0.5
    F1 лучшей модели (LogisticRegression): 0.469
    при уменьшении на: х_ 0.6
    F1 лучшей модели (LogisticRegression): 0.432
    при уменьшении на: х_ 0.7000000000000001
    F1 лучшей модели (LogisticRegression): 0.391
    при уменьшении на: х_ 0.8
    F1 лучшей модели (LogisticRegression): 0.368
    

## Вывод

1. Наибольший прирост F1 по DecisionTreeClassifier_model, при уменьшении выборки, дает МНОЖИТЕЛЬ - х0.6
2. Наибольший прирост F1 по RandomForestClassifier_model, при уменьшении выборки, дает МНОЖИТЕЛЬ - х0.3
3. Наибольший прирост F1 по LogisticRegression_model, при уменьшении выборки, дает МНОЖИТЕЛЬ - х0.4

## Тестирование модели


```python
# увеличение выборки (МНОЖИТЕЛЬ - х3)
f_х3, t_х3 = upsample(features_train, target_train, 3)
```


```python
#  уменьшение выборки (МНОЖИТЕЛЬ - х0.6)
f_х06, t_х06 = downsample(features_train, target_train, 0.6)
```


```python
#  уменьшение выборки (МНОЖИТЕЛЬ - х0.3)
f_х03, t_х03 = downsample(features_train, target_train, 0.3)
```


```python
#  уменьшение выборки (МНОЖИТЕЛЬ - х0.4)
f_х04, t_х04 = downsample(features_train, target_train, 0.4)
```


```python
# лист из
# 3-х лучших моделей на уменьшенной выборке (МНОЖИТЕЛЬ - х0.6)
# 3-х лучших моделей на уменьшенной выборке (МНОЖИТЕЛЬ - х0.3)
# 3-х лучших моделей на уменьшенной выборке (МНОЖИТЕЛЬ - х0.4)
# 3-х лучших моделей на увеличенной выборке (МНОЖИТЕЛЬ - х3)

list_model = [DecisionTreeClassifier_model(f_х06, t_х06), RandomForestClassifier_model(f_х06, t_х06), LogisticRegression_model(f_х06, t_х06),
              DecisionTreeClassifier_model(f_х03, t_х03), RandomForestClassifier_model(f_х03, t_х03), LogisticRegression_model(f_х03, t_х03),
              DecisionTreeClassifier_model(f_х04, t_х04), RandomForestClassifier_model(f_х04, t_х04), LogisticRegression_model(f_х04, t_х04),
              DecisionTreeClassifier_model(f_х3, t_х3), RandomForestClassifier_model(f_х3, t_х3), LogisticRegression_model(f_х3, t_х3)]
```

    F1 лучшей модели (DecisionTreeClassifier): 0.587
    F1 лучшей модели (RandomForestClassifier): 0.594
    F1 лучшей модели (LogisticRegression): 0.432
    F1 лучшей модели (DecisionTreeClassifier): 0.579
    F1 лучшей модели (RandomForestClassifier): 0.621
    F1 лучшей модели (LogisticRegression): 0.497
    F1 лучшей модели (DecisionTreeClassifier): 0.569
    F1 лучшей модели (RandomForestClassifier): 0.609
    F1 лучшей модели (LogisticRegression): 0.505
    F1 лучшей модели (DecisionTreeClassifier): 0.586
    F1 лучшей модели (RandomForestClassifier): 0.612
    F1 лучшей модели (LogisticRegression): 0.5
    


```python
list_model
```




    [DecisionTreeClassifier(max_depth=8, random_state=12345),
     RandomForestClassifier(max_depth=4, n_estimators=9, random_state=12345),
     LogisticRegression(max_iter=1000, random_state=12345, solver='liblinear'),
     DecisionTreeClassifier(max_depth=5, random_state=12345),
     RandomForestClassifier(max_depth=5, n_estimators=10, random_state=12345),
     LogisticRegression(max_iter=1000, random_state=12345, solver='saga'),
     DecisionTreeClassifier(max_depth=7, random_state=12345),
     RandomForestClassifier(max_depth=5, n_estimators=9, random_state=12345),
     LogisticRegression(max_iter=1000, random_state=12345, solver='saga'),
     DecisionTreeClassifier(max_depth=5, random_state=12345),
     RandomForestClassifier(max_depth=5, n_estimators=10, random_state=12345),
     LogisticRegression(max_iter=1000, random_state=12345, solver='saga')]




```python
# поиск наилучшей модели на ТЕСТОВОЙ выборке
best_model = None
best_result = 0
for mod in list_model:
  test_predictions = mod.predict(features_test)
  result = f1_score(target_test, test_predictions)
  if best_result < result:
    best_result = result
    best_model = mod
    print("F1 =", round(best_result, 3), "-", best_model)

print("____________________________________________________________________________________________")
print("НАИЛУЧШАЯ модель на ТЕСТОВОЙ выборке:", best_model)
print("F1 =", round(best_result, 3))
```

    F1 = 0.569 - DecisionTreeClassifier(max_depth=8, random_state=12345)
    F1 = 0.591 - DecisionTreeClassifier(max_depth=5, random_state=12345)
    ____________________________________________________________________________________________
    НАИЛУЧШАЯ модель на ТЕСТОВОЙ выборке: DecisionTreeClassifier(max_depth=5, random_state=12345)
    F1 = 0.591
    


```python
# построение кривой ошибок
model = best_model
model.fit(features_train, target_train)

probabilities_valid = model.predict_proba(features_valid)
probabilities_one_valid = probabilities_valid[:, 1]

fpr, tpr, thresholds = roc_curve(target_valid, probabilities_one_valid) 

plt.figure()

plt.plot(fpr, tpr)

plt.plot([0, 1], [0, 1], linestyle='--')

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')

plt.title('ROC-кривая')

plt.show()
```


    
![png](output_54_0.png)
    



```python
# площадь под кривой ошибок
auc_roc = roc_auc_score(target_valid, probabilities_one_valid)

print("Площадь под ROC-кривой:", round(auc_roc, 3))
```

    Площадь под ROC-кривой: 0.822
    

# Общий вывод

**В результате подготовки данных, установлено:**

1. Пропусков в столбце "Tenure" порядка 9% (проведена замена на медианные значения).
2. Необходимо удалить столбцы 'CustomerId', 'RowNumber', 'Surname' из признаков (они не несут полезной информации для предсказания).

**В результате исследования:**

1. Соотношение в данных 8:2.
2. Проведено порядковое кодирование (применение прямого привело бы к излишне большому количеству столбцов, что не к чему).
3. Применено масштабирование к столбцам 'CreditScore', 'Age', 'Tenure', 'Balance','EstimatedSalary'.
4. Выполнено деление на обучающую и валидационно-тестовую выборку (60:40).
5. Выполнено деление валидационно-тестовой выборки (50:50).
6. Установлено F1 лучшей модели (DecisionTreeClassifier): 0.57 с параметрами (max_depth=6, random_state=12345).
7. Установлено F1 лучшей модели (RandomForestClassifier): 0.538 с параметрами (max_depth=4, n_estimators=9, random_state=12345).
8. Установлено F1 лучшей модели (LogisticRegression): 0.331 с параметрами (max_iter=1000, random_state=12345, solver='saga').
9. В среднем наибольший прирост F1 по всем моделям, при увеличении выборки, дает МНОЖИТЕЛЬ - х3
10. Наибольший прирост F1 по DecisionTreeClassifier_model, при уменьшении выборки, дает МНОЖИТЕЛЬ - х0.6
11. Наибольший прирост F1 по RandomForestClassifier_model, при уменьшении выборки, дает МНОЖИТЕЛЬ - х0.3
12. Наибольший прирост F1 по LogisticRegression_model, при уменьшении выборки, дает МНОЖИТЕЛЬ - х0.4

**В результате тестирования, установлено:**
1. Наилучшая модель на тестовой выборке: DecisionTreeClassifier
2. Параметры модели: max_depth=5, random_state=12345
3. Значение F1 = 0.591
4. Площадь под ROC-кривой: 0.822
